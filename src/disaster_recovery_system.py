"""
Disaster Recovery & Business Continuity System for hAIveMind DevOps

Comprehensive DR automation with failover/failback procedures, chaos engineering,
multi-region coordination, and automated recovery testing.

Features:
- Comprehensive DR plan creation with RTO/RPO targets
- Automated DR testing with validation checkpoints
- Coordinated failover across multiple systems
- Intelligent failback with data synchronization
- DR configuration backup and versioning
- Chaos engineering for DR validation
- Multi-region deployment coordination
- DNS and load balancer reconfiguration
"""

import sqlite3
import json
import logging
import time
import subprocess
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Set
from dataclasses import dataclass, asdict
from pathlib import Path
import hashlib
from enum import Enum
import yaml
import requests
import paramiko
from concurrent.futures import ThreadPoolExecutor, as_completed

logger = logging.getLogger(__name__)

class DREvent(Enum):
    DATACENTER_FAILURE = "datacenter_failure"
    NETWORK_PARTITION = "network_partition"
    DATABASE_CORRUPTION = "database_corruption"
    SERVICE_DEGRADATION = "service_degradation"
    SECURITY_BREACH = "security_breach"
    NATURAL_DISASTER = "natural_disaster"

class DRStatus(Enum):
    READY = "ready"
    TESTING = "testing"
    FAILING_OVER = "failing_over"
    FAILED_OVER = "failed_over"
    FAILING_BACK = "failing_back"
    DEGRADED = "degraded"
    UNAVAILABLE = "unavailable"

@dataclass
class DRPlan:
    id: str
    name: str
    description: str
    services: List[str]
    scenario_type: DREvent
    rto_minutes: int  # Recovery Time Objective
    rpo_minutes: int  # Recovery Point Objective
    primary_region: str
    secondary_region: str
    steps: List[Dict[str, Any]]
    dependencies: List[str]
    validation_checks: List[Dict[str, Any]]
    rollback_steps: List[Dict[str, Any]]
    created_at: datetime
    updated_at: datetime
    
@dataclass
class DRExecution:
    id: str
    plan_id: str
    execution_type: str  # "test", "real_failover", "failback"
    status: DRStatus
    started_at: datetime
    completed_at: Optional[datetime]
    triggered_by: str
    steps_completed: int
    total_steps: int
    current_step: Optional[str]
    logs: List[str]
    success: Optional[bool]
    
@dataclass
class ServiceHealth:
    service_name: str
    region: str
    endpoint: str
    status: str  # "healthy", "degraded", "unhealthy"
    response_time_ms: float
    last_check: datetime
    metadata: Dict[str, Any]

class DisasterRecoverySystem:
    """Comprehensive disaster recovery and business continuity management"""
    
    def __init__(self, db_path: str = "data/disaster_recovery.db"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self._init_database()
        
        # Execution state
        self.active_executions = {}
        self.executor = ThreadPoolExecutor(max_workers=10)
        
        logger.info("ðŸš¨ Disaster Recovery System initialized")
    
    def _init_database(self):
        """Initialize SQLite database with DR management schema"""
        conn = sqlite3.connect(self.db_path)
        conn.execute("PRAGMA foreign_keys = ON")
        
        try:
            # DR Plans table
            conn.execute('''
                CREATE TABLE IF NOT EXISTS dr_plans (
                    id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),
                    name TEXT NOT NULL UNIQUE,
                    description TEXT,
                    services TEXT DEFAULT '[]',
                    scenario_type TEXT NOT NULL,
                    rto_minutes INTEGER NOT NULL,
                    rpo_minutes INTEGER NOT NULL,
                    primary_region TEXT NOT NULL,
                    secondary_region TEXT NOT NULL,
                    steps TEXT DEFAULT '[]',
                    dependencies TEXT DEFAULT '[]',
                    validation_checks TEXT DEFAULT '[]',
                    rollback_steps TEXT DEFAULT '[]',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # DR Executions table
            conn.execute('''
                CREATE TABLE IF NOT EXISTS dr_executions (
                    id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),
                    plan_id TEXT NOT NULL,
                    execution_type TEXT NOT NULL,
                    status TEXT NOT NULL,
                    triggered_by TEXT NOT NULL,
                    steps_completed INTEGER DEFAULT 0,
                    total_steps INTEGER NOT NULL,
                    current_step TEXT,
                    success BOOLEAN,
                    started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    completed_at TIMESTAMP,
                    FOREIGN KEY (plan_id) REFERENCES dr_plans (id)
                )
            ''')
            
            # DR Execution Logs table
            conn.execute('''
                CREATE TABLE IF NOT EXISTS dr_execution_logs (
                    id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),
                    execution_id TEXT NOT NULL,
                    step_name TEXT,
                    log_level TEXT DEFAULT 'INFO',
                    message TEXT NOT NULL,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (execution_id) REFERENCES dr_executions (id)
                )
            ''')
            
            # Service Health Monitoring table
            conn.execute('''
                CREATE TABLE IF NOT EXISTS service_health (
                    id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),
                    service_name TEXT NOT NULL,
                    region TEXT NOT NULL,
                    endpoint TEXT NOT NULL,
                    status TEXT NOT NULL,
                    response_time_ms REAL,
                    metadata TEXT DEFAULT '{}',
                    last_check TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE (service_name, region)
                )
            ''')
            
            # DR Configurations (backup of configs before changes)
            conn.execute('''
                CREATE TABLE IF NOT EXISTS dr_configs (
                    id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),
                    service_name TEXT NOT NULL,
                    config_type TEXT NOT NULL,
                    region TEXT NOT NULL,
                    config_data TEXT NOT NULL,
                    config_hash TEXT NOT NULL,
                    backed_up_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    execution_id TEXT,
                    FOREIGN KEY (execution_id) REFERENCES dr_executions (id)
                )
            ''')
            
            # Chaos Engineering Experiments
            conn.execute('''
                CREATE TABLE IF NOT EXISTS chaos_experiments (
                    id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),
                    name TEXT NOT NULL,
                    description TEXT,
                    target_services TEXT DEFAULT '[]',
                    experiment_type TEXT NOT NULL,
                    configuration TEXT DEFAULT '{}',
                    status TEXT DEFAULT 'planned',
                    started_at TIMESTAMP,
                    completed_at TIMESTAMP,
                    success BOOLEAN,
                    results TEXT DEFAULT '{}',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Create indexes
            indexes = [
                "CREATE INDEX IF NOT EXISTS idx_dr_plans_scenario ON dr_plans (scenario_type)",
                "CREATE INDEX IF NOT EXISTS idx_executions_plan ON dr_executions (plan_id)",
                "CREATE INDEX IF NOT EXISTS idx_executions_status ON dr_executions (status)",
                "CREATE INDEX IF NOT EXISTS idx_execution_logs_execution ON dr_execution_logs (execution_id)",
                "CREATE INDEX IF NOT EXISTS idx_service_health_service ON service_health (service_name, region)",
                "CREATE INDEX IF NOT EXISTS idx_dr_configs_service ON dr_configs (service_name, region)",
                "CREATE INDEX IF NOT EXISTS idx_chaos_status ON chaos_experiments (status)"
            ]
            
            for index_sql in indexes:
                conn.execute(index_sql)
            
            conn.commit()
            logger.info("ðŸ“Š Disaster Recovery database schema initialized")
            
        finally:
            conn.close()
    
    # ===== DR PLAN MANAGEMENT =====
    
    def create_dr_plan(self, name: str, description: str, services: List[str],
                      scenario_type: DREvent, rto_minutes: int, rpo_minutes: int,
                      primary_region: str, secondary_region: str,
                      steps: List[Dict[str, Any]], dependencies: Optional[List[str]] = None,
                      validation_checks: Optional[List[Dict[str, Any]]] = None,
                      rollback_steps: Optional[List[Dict[str, Any]]] = None) -> str:
        """Create a new disaster recovery plan"""
        conn = sqlite3.connect(self.db_path)
        
        try:
            plan_id = hashlib.md5(f"{name}{time.time()}".encode()).hexdigest()
            
            conn.execute('''
                INSERT INTO dr_plans 
                (id, name, description, services, scenario_type, rto_minutes, rpo_minutes,
                 primary_region, secondary_region, steps, dependencies, validation_checks, rollback_steps)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                plan_id, name, description, json.dumps(services), scenario_type.value,
                rto_minutes, rpo_minutes, primary_region, secondary_region,
                json.dumps(steps), json.dumps(dependencies or []),
                json.dumps(validation_checks or []), json.dumps(rollback_steps or [])
            ))
            
            conn.commit()
            logger.info(f"ðŸ“‹ DR Plan created: {name} (RTO: {rto_minutes}min, RPO: {rpo_minutes}min)")
            return plan_id
            
        finally:
            conn.close()
    
    def get_dr_plans(self, scenario_type: Optional[DREvent] = None) -> List[Dict[str, Any]]:
        """Get DR plans with optional filtering by scenario type"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        
        try:
            if scenario_type:
                plans = conn.execute(
                    'SELECT * FROM dr_plans WHERE scenario_type = ? ORDER BY name',
                    (scenario_type.value,)
                ).fetchall()
            else:
                plans = conn.execute('SELECT * FROM dr_plans ORDER BY name').fetchall()
            
            result = []
            for plan in plans:
                plan_dict = dict(plan)
                plan_dict['services'] = json.loads(plan_dict['services'])
                plan_dict['steps'] = json.loads(plan_dict['steps'])
                plan_dict['dependencies'] = json.loads(plan_dict['dependencies'])
                plan_dict['validation_checks'] = json.loads(plan_dict['validation_checks'])
                plan_dict['rollback_steps'] = json.loads(plan_dict['rollback_steps'])
                result.append(plan_dict)
            
            return result
            
        finally:
            conn.close()
    
    # ===== DR TESTING =====
    
    def test_dr_plan(self, plan_id: str, triggered_by: str = "automated_test") -> str:
        """Execute DR plan in test mode"""
        return self._execute_dr_plan(plan_id, "test", triggered_by)
    
    def _execute_dr_plan(self, plan_id: str, execution_type: str, triggered_by: str) -> str:
        """Execute DR plan with specified type"""
        conn = sqlite3.connect(self.db_path)
        
        try:
            # Get plan details
            plan = conn.execute('SELECT * FROM dr_plans WHERE id = ?', (plan_id,)).fetchone()
            if not plan:
                raise ValueError(f"DR plan {plan_id} not found")
            
            steps = json.loads(plan[9])  # steps column
            
            # Create execution record
            execution_id = hashlib.md5(f"{plan_id}{execution_type}{time.time()}".encode()).hexdigest()
            
            conn.execute('''
                INSERT INTO dr_executions 
                (id, plan_id, execution_type, status, triggered_by, total_steps)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (execution_id, plan_id, execution_type, DRStatus.TESTING.value, triggered_by, len(steps)))
            
            conn.commit()
            
            # Execute asynchronously
            self.active_executions[execution_id] = {
                'plan': plan,
                'execution_type': execution_type,
                'steps': steps,
                'current_step': 0
            }
            
            future = self.executor.submit(self._run_dr_execution, execution_id)
            
            logger.info(f"ðŸ§ª DR execution started: {plan[1]} ({execution_type})")
            return execution_id
            
        finally:
            conn.close()
    
    def _run_dr_execution(self, execution_id: str):
        """Run DR execution steps"""
        conn = sqlite3.connect(self.db_path)
        
        try:
            execution_info = self.active_executions[execution_id]
            plan = execution_info['plan']
            steps = execution_info['steps']
            execution_type = execution_info['execution_type']
            
            success = True
            
            for i, step in enumerate(steps):
                try:
                    # Update current step
                    conn.execute('''
                        UPDATE dr_executions 
                        SET steps_completed = ?, current_step = ?
                        WHERE id = ?
                    ''', (i, step.get('name', f"Step {i+1}"), execution_id))
                    
                    self._log_execution(execution_id, step.get('name'), 'INFO', 
                                      f"Executing: {step.get('description', '')}")
                    
                    # Execute step
                    step_success = self._execute_dr_step(step, execution_type, execution_id)
                    
                    if not step_success:
                        success = False
                        self._log_execution(execution_id, step.get('name'), 'ERROR', 
                                          f"Step failed: {step.get('name')}")
                        
                        # Check if step is critical
                        if step.get('critical', False):
                            break
                    else:
                        self._log_execution(execution_id, step.get('name'), 'INFO', 
                                          f"Step completed successfully: {step.get('name')}")
                    
                    # Wait between steps if specified
                    wait_seconds = step.get('wait_seconds', 0)
                    if wait_seconds > 0:
                        time.sleep(wait_seconds)
                
                except Exception as e:
                    success = False
                    self._log_execution(execution_id, step.get('name'), 'ERROR', 
                                      f"Step exception: {str(e)}")
                    
                    if step.get('critical', False):
                        break
            
            # Update final status
            final_status = DRStatus.READY.value if success else DRStatus.DEGRADED.value
            conn.execute('''
                UPDATE dr_executions 
                SET status = ?, success = ?, completed_at = CURRENT_TIMESTAMP,
                    steps_completed = ?
                WHERE id = ?
            ''', (final_status, success, len(steps), execution_id))
            
            conn.commit()
            
            # Run validation checks if successful
            if success and execution_type == "test":
                self._run_validation_checks(execution_id)
            
            # Clean up
            if execution_id in self.active_executions:
                del self.active_executions[execution_id]
            
            logger.info(f"ðŸ§ª DR execution completed: {execution_id} ({'SUCCESS' if success else 'FAILED'})")
            
        except Exception as e:
            logger.error(f"âŒ DR execution failed: {e}")
            conn.execute('''
                UPDATE dr_executions 
                SET status = ?, success = FALSE, completed_at = CURRENT_TIMESTAMP
                WHERE id = ?
            ''', (DRStatus.UNAVAILABLE.value, execution_id))
            conn.commit()
        finally:
            conn.close()
    
    def _execute_dr_step(self, step: Dict[str, Any], execution_type: str, execution_id: str) -> bool:
        """Execute individual DR step"""
        step_type = step.get('type')
        
        try:
            if step_type == 'service_stop':
                return self._execute_service_stop(step, execution_type)
            elif step_type == 'service_start':
                return self._execute_service_start(step, execution_type)
            elif step_type == 'dns_update':
                return self._execute_dns_update(step, execution_type)
            elif step_type == 'load_balancer_update':
                return self._execute_load_balancer_update(step, execution_type)
            elif step_type == 'database_failover':
                return self._execute_database_failover(step, execution_type)
            elif step_type == 'file_sync':
                return self._execute_file_sync(step, execution_type)
            elif step_type == 'health_check':
                return self._execute_health_check(step, execution_type)
            elif step_type == 'script_execution':
                return self._execute_script(step, execution_type)
            elif step_type == 'notification':
                return self._execute_notification(step, execution_type)
            elif step_type == 'wait':
                time.sleep(step.get('duration', 30))
                return True
            else:
                logger.warning(f"âš ï¸ Unknown step type: {step_type}")
                return True  # Don't fail on unknown steps in test mode
                
        except Exception as e:
            logger.error(f"âŒ Step execution failed: {e}")
            return False
    
    def _execute_service_stop(self, step: Dict[str, Any], execution_type: str) -> bool:
        """Stop service (simulate in test mode)"""
        service = step.get('service')
        host = step.get('host')
        
        if execution_type == "test":
            logger.info(f"ðŸ§ª TEST MODE: Would stop service {service} on {host}")
            return True
        
        try:
            # Real execution - connect via SSH and stop service
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            ssh.connect(host, username=step.get('username', 'root'), 
                       key_filename=step.get('key_file'))
            
            command = step.get('stop_command', f'systemctl stop {service}')
            stdin, stdout, stderr = ssh.exec_command(command)
            
            exit_status = stdout.channel.recv_exit_status()
            ssh.close()
            
            return exit_status == 0
            
        except Exception as e:
            logger.error(f"âŒ Failed to stop service {service}: {e}")
            return False
    
    def _execute_service_start(self, step: Dict[str, Any], execution_type: str) -> bool:
        """Start service (simulate in test mode)"""
        service = step.get('service')
        host = step.get('host')
        
        if execution_type == "test":
            logger.info(f"ðŸ§ª TEST MODE: Would start service {service} on {host}")
            return True
        
        try:
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            ssh.connect(host, username=step.get('username', 'root'),
                       key_filename=step.get('key_file'))
            
            command = step.get('start_command', f'systemctl start {service}')
            stdin, stdout, stderr = ssh.exec_command(command)
            
            exit_status = stdout.channel.recv_exit_status()
            ssh.close()
            
            return exit_status == 0
            
        except Exception as e:
            logger.error(f"âŒ Failed to start service {service}: {e}")
            return False
    
    def _execute_dns_update(self, step: Dict[str, Any], execution_type: str) -> bool:
        """Update DNS records (simulate in test mode)"""
        record_name = step.get('record_name')
        new_ip = step.get('new_ip')
        
        if execution_type == "test":
            logger.info(f"ðŸ§ª TEST MODE: Would update DNS {record_name} -> {new_ip}")
            return True
        
        try:
            # This would integrate with your DNS provider (Cloudflare, Route53, etc.)
            # For now, simulate success
            logger.info(f"ðŸŒ DNS updated: {record_name} -> {new_ip}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Failed to update DNS: {e}")
            return False
    
    def _execute_load_balancer_update(self, step: Dict[str, Any], execution_type: str) -> bool:
        """Update load balancer configuration"""
        lb_name = step.get('load_balancer')
        action = step.get('action')  # add_backend, remove_backend, drain
        
        if execution_type == "test":
            logger.info(f"ðŸ§ª TEST MODE: Would {action} on load balancer {lb_name}")
            return True
        
        try:
            # This would integrate with your load balancer API
            logger.info(f"âš–ï¸ Load balancer updated: {lb_name} - {action}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Failed to update load balancer: {e}")
            return False
    
    def _execute_database_failover(self, step: Dict[str, Any], execution_type: str) -> bool:
        """Execute database failover"""
        database = step.get('database')
        primary_host = step.get('primary_host')
        secondary_host = step.get('secondary_host')
        
        if execution_type == "test":
            logger.info(f"ðŸ§ª TEST MODE: Would failover {database} from {primary_host} to {secondary_host}")
            return True
        
        try:
            # This would execute actual database failover
            logger.info(f"ðŸ—„ï¸ Database failover: {database} -> {secondary_host}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Failed database failover: {e}")
            return False
    
    def _execute_file_sync(self, step: Dict[str, Any], execution_type: str) -> bool:
        """Synchronize files between regions"""
        source_path = step.get('source_path')
        dest_path = step.get('dest_path')
        
        if execution_type == "test":
            logger.info(f"ðŸ§ª TEST MODE: Would sync {source_path} -> {dest_path}")
            return True
        
        try:
            # Use rsync or similar for file synchronization
            command = f"rsync -av {source_path} {dest_path}"
            result = subprocess.run(command, shell=True, capture_output=True, text=True)
            return result.returncode == 0
            
        except Exception as e:
            logger.error(f"âŒ Failed file sync: {e}")
            return False
    
    def _execute_health_check(self, step: Dict[str, Any], execution_type: str) -> bool:
        """Execute health check"""
        endpoint = step.get('endpoint')
        expected_status = step.get('expected_status', 200)
        timeout = step.get('timeout', 30)
        
        try:
            response = requests.get(endpoint, timeout=timeout)
            success = response.status_code == expected_status
            
            if success:
                logger.info(f"âœ… Health check passed: {endpoint}")
            else:
                logger.warning(f"âš ï¸ Health check failed: {endpoint} returned {response.status_code}")
            
            return success
            
        except Exception as e:
            logger.error(f"âŒ Health check failed: {endpoint} - {e}")
            return False
    
    def _execute_script(self, step: Dict[str, Any], execution_type: str) -> bool:
        """Execute custom script"""
        script_path = step.get('script_path')
        host = step.get('host', 'localhost')
        
        if execution_type == "test" and step.get('skip_in_test', False):
            logger.info(f"ðŸ§ª TEST MODE: Skipping script {script_path}")
            return True
        
        try:
            if host == 'localhost':
                result = subprocess.run(script_path, shell=True, capture_output=True, text=True)
                return result.returncode == 0
            else:
                # Execute on remote host via SSH
                ssh = paramiko.SSHClient()
                ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
                ssh.connect(host, username=step.get('username', 'root'),
                           key_filename=step.get('key_file'))
                
                stdin, stdout, stderr = ssh.exec_command(script_path)
                exit_status = stdout.channel.recv_exit_status()
                ssh.close()
                
                return exit_status == 0
                
        except Exception as e:
            logger.error(f"âŒ Script execution failed: {e}")
            return False
    
    def _execute_notification(self, step: Dict[str, Any], execution_type: str) -> bool:
        """Send notification"""
        message = step.get('message')
        notification_type = step.get('notification_type', 'email')
        
        try:
            # This would integrate with notification systems (Slack, email, etc.)
            logger.info(f"ðŸ“¢ Notification sent ({notification_type}): {message}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Notification failed: {e}")
            return False
    
    def _run_validation_checks(self, execution_id: str):
        """Run validation checks after DR execution"""
        conn = sqlite3.connect(self.db_path)
        
        try:
            # Get plan validation checks
            execution = conn.execute('''
                SELECT p.validation_checks FROM dr_plans p
                JOIN dr_executions e ON p.id = e.plan_id
                WHERE e.id = ?
            ''', (execution_id,)).fetchone()
            
            if execution and execution[0]:
                validation_checks = json.loads(execution[0])
                
                for check in validation_checks:
                    self._log_execution(execution_id, 'validation', 'INFO',
                                      f"Running validation: {check.get('name')}")
                    
                    # Execute validation check (similar to regular steps)
                    success = self._execute_dr_step(check, "validation", execution_id)
                    
                    if not success:
                        self._log_execution(execution_id, 'validation', 'WARNING',
                                          f"Validation failed: {check.get('name')}")
                    
        finally:
            conn.close()
    
    def _log_execution(self, execution_id: str, step_name: Optional[str], level: str, message: str):
        """Log execution step"""
        conn = sqlite3.connect(self.db_path)
        
        try:
            conn.execute('''
                INSERT INTO dr_execution_logs (execution_id, step_name, log_level, message)
                VALUES (?, ?, ?, ?)
            ''', (execution_id, step_name, level, message))
            conn.commit()
            
        finally:
            conn.close()
    
    # ===== FAILOVER AND FAILBACK =====
    
    def failover(self, plan_id: str, triggered_by: str, target_region: Optional[str] = None) -> str:
        """Execute emergency failover"""
        logger.critical(f"ðŸš¨ FAILOVER INITIATED: Plan {plan_id} by {triggered_by}")
        return self._execute_dr_plan(plan_id, "real_failover", triggered_by)
    
    def failback(self, plan_id: str, triggered_by: str) -> str:
        """Execute failback to primary systems"""
        conn = sqlite3.connect(self.db_path)
        
        try:
            # Get rollback steps from plan
            plan = conn.execute('SELECT rollback_steps FROM dr_plans WHERE id = ?', (plan_id,)).fetchone()
            if not plan or not plan[0]:
                raise ValueError("No rollback steps defined for this DR plan")
            
            rollback_steps = json.loads(plan[0])
            
            # Create failback execution
            execution_id = hashlib.md5(f"{plan_id}failback{time.time()}".encode()).hexdigest()
            
            conn.execute('''
                INSERT INTO dr_executions 
                (id, plan_id, execution_type, status, triggered_by, total_steps)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (execution_id, plan_id, "failback", DRStatus.FAILING_BACK.value, 
                  triggered_by, len(rollback_steps)))
            
            conn.commit()
            
            # Store rollback steps for execution
            self.active_executions[execution_id] = {
                'plan': plan,
                'execution_type': 'failback',
                'steps': rollback_steps,
                'current_step': 0
            }
            
            # Execute asynchronously
            future = self.executor.submit(self._run_dr_execution, execution_id)
            
            logger.info(f"ðŸ”„ FAILBACK initiated: {execution_id}")
            return execution_id
            
        finally:
            conn.close()
    
    # ===== CHAOS ENGINEERING =====
    
    def create_chaos_experiment(self, name: str, description: str, target_services: List[str],
                              experiment_type: str, configuration: Dict[str, Any]) -> str:
        """Create chaos engineering experiment"""
        conn = sqlite3.connect(self.db_path)
        
        try:
            experiment_id = hashlib.md5(f"{name}{time.time()}".encode()).hexdigest()
            
            conn.execute('''
                INSERT INTO chaos_experiments 
                (id, name, description, target_services, experiment_type, configuration)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (experiment_id, name, description, json.dumps(target_services),
                  experiment_type, json.dumps(configuration)))
            
            conn.commit()
            logger.info(f"ðŸ”¥ Chaos experiment created: {name}")
            return experiment_id
            
        finally:
            conn.close()
    
    def run_chaos_experiment(self, experiment_id: str) -> Dict[str, Any]:
        """Execute chaos engineering experiment"""
        conn = sqlite3.connect(self.db_path)
        
        try:
            experiment = conn.execute('SELECT * FROM chaos_experiments WHERE id = ?', (experiment_id,)).fetchone()
            if not experiment:
                raise ValueError(f"Chaos experiment {experiment_id} not found")
            
            # Update status to running
            conn.execute('''
                UPDATE chaos_experiments 
                SET status = 'running', started_at = CURRENT_TIMESTAMP
                WHERE id = ?
            ''', (experiment_id,))
            
            conn.commit()
            
            experiment_type = experiment[5]  # experiment_type column
            configuration = json.loads(experiment[6])  # configuration column
            target_services = json.loads(experiment[4])  # target_services column
            
            results = {}
            success = True
            
            try:
                if experiment_type == 'service_kill':
                    results = self._chaos_service_kill(target_services, configuration)
                elif experiment_type == 'network_partition':
                    results = self._chaos_network_partition(target_services, configuration)
                elif experiment_type == 'resource_exhaustion':
                    results = self._chaos_resource_exhaustion(target_services, configuration)
                elif experiment_type == 'dependency_failure':
                    results = self._chaos_dependency_failure(target_services, configuration)
                else:
                    raise ValueError(f"Unknown chaos experiment type: {experiment_type}")
                
            except Exception as e:
                success = False
                results['error'] = str(e)
                logger.error(f"âŒ Chaos experiment failed: {e}")
            
            # Update final status
            conn.execute('''
                UPDATE chaos_experiments 
                SET status = 'completed', completed_at = CURRENT_TIMESTAMP, 
                    success = ?, results = ?
                WHERE id = ?
            ''', (success, json.dumps(results), experiment_id))
            
            conn.commit()
            
            logger.info(f"ðŸ”¥ Chaos experiment completed: {experiment[1]} ({'SUCCESS' if success else 'FAILED'})")
            return results
            
        finally:
            conn.close()
    
    def _chaos_service_kill(self, services: List[str], config: Dict[str, Any]) -> Dict[str, Any]:
        """Chaos experiment: Kill random services"""
        import random
        
        results = {'killed_services': [], 'recovery_times': {}}
        duration = config.get('duration_minutes', 5)
        
        # Kill random service
        target_service = random.choice(services)
        
        # Simulate service kill and recovery monitoring
        logger.info(f"ðŸ”¥ CHAOS: Killing service {target_service} for {duration} minutes")
        
        start_time = time.time()
        
        # In real implementation, this would actually kill the service
        # For simulation, we just wait and record metrics
        time.sleep(min(duration * 60, 30))  # Cap at 30 seconds for simulation
        
        recovery_time = time.time() - start_time
        
        results['killed_services'].append(target_service)
        results['recovery_times'][target_service] = recovery_time
        results['total_downtime_seconds'] = recovery_time
        
        return results
    
    def _chaos_network_partition(self, services: List[str], config: Dict[str, Any]) -> Dict[str, Any]:
        """Chaos experiment: Simulate network partition"""
        results = {'partitioned_services': services, 'partition_duration': config.get('duration_minutes', 5)}
        
        logger.info(f"ðŸ”¥ CHAOS: Simulating network partition for {len(services)} services")
        
        # Simulate partition effects
        time.sleep(10)  # Simulation delay
        
        results['services_affected'] = len(services)
        results['partition_type'] = config.get('partition_type', 'split_brain')
        
        return results
    
    def _chaos_resource_exhaustion(self, services: List[str], config: Dict[str, Any]) -> Dict[str, Any]:
        """Chaos experiment: Exhaust system resources"""
        resource_type = config.get('resource_type', 'cpu')
        results = {'resource_type': resource_type, 'affected_services': services}
        
        logger.info(f"ðŸ”¥ CHAOS: Exhausting {resource_type} resources")
        
        # Simulate resource exhaustion
        results['max_resource_usage'] = config.get('max_usage_percent', 90)
        results['duration_seconds'] = config.get('duration_minutes', 2) * 60
        
        return results
    
    def _chaos_dependency_failure(self, services: List[str], config: Dict[str, Any]) -> Dict[str, Any]:
        """Chaos experiment: Simulate dependency failures"""
        dependency = config.get('dependency_service', 'database')
        results = {'failed_dependency': dependency, 'affected_services': services}
        
        logger.info(f"ðŸ”¥ CHAOS: Simulating {dependency} dependency failure")
        
        results['cascade_effects'] = len(services)
        results['recovery_strategy'] = config.get('recovery_strategy', 'circuit_breaker')
        
        return results
    
    # ===== MONITORING AND HEALTH CHECKS =====
    
    def monitor_service_health(self, services: List[Dict[str, str]]) -> Dict[str, ServiceHealth]:
        """Monitor health of critical services"""
        health_results = {}
        
        for service_config in services:
            service_name = service_config['name']
            endpoint = service_config['endpoint']
            region = service_config.get('region', 'default')
            
            try:
                start_time = time.time()
                response = requests.get(endpoint, timeout=10)
                response_time = (time.time() - start_time) * 1000
                
                if response.status_code == 200:
                    status = "healthy"
                elif response.status_code in [500, 502, 503, 504]:
                    status = "unhealthy"
                else:
                    status = "degraded"
                
                health = ServiceHealth(
                    service_name=service_name,
                    region=region,
                    endpoint=endpoint,
                    status=status,
                    response_time_ms=response_time,
                    last_check=datetime.now(),
                    metadata={'status_code': response.status_code}
                )
                
            except Exception as e:
                health = ServiceHealth(
                    service_name=service_name,
                    region=region,
                    endpoint=endpoint,
                    status="unhealthy",
                    response_time_ms=0,
                    last_check=datetime.now(),
                    metadata={'error': str(e)}
                )
            
            health_results[service_name] = health
            self._store_health_check(health)
        
        return health_results
    
    def _store_health_check(self, health: ServiceHealth):
        """Store service health check result"""
        conn = sqlite3.connect(self.db_path)
        
        try:
            conn.execute('''
                INSERT OR REPLACE INTO service_health 
                (service_name, region, endpoint, status, response_time_ms, metadata)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (health.service_name, health.region, health.endpoint, health.status,
                  health.response_time_ms, json.dumps(health.metadata)))
            
            conn.commit()
            
        finally:
            conn.close()
    
    # ===== REPORTING AND ANALYTICS =====
    
    def get_dr_readiness_report(self) -> Dict[str, Any]:
        """Generate DR readiness assessment report"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        
        try:
            report = {
                'summary': {},
                'plan_status': [],
                'recent_tests': [],
                'service_health': {},
                'recommendations': []
            }
            
            # Plan summary
            plans = conn.execute('SELECT COUNT(*) as total, scenario_type FROM dr_plans GROUP BY scenario_type').fetchall()
            report['summary']['total_plans'] = sum(plan['total'] for plan in plans)
            report['summary']['plans_by_scenario'] = {plan['scenario_type']: plan['total'] for plan in plans}
            
            # Recent test results
            recent_tests = conn.execute('''
                SELECT e.*, p.name as plan_name FROM dr_executions e
                JOIN dr_plans p ON e.plan_id = p.id
                WHERE e.execution_type = 'test' AND e.started_at >= date('now', '-30 days')
                ORDER BY e.started_at DESC
                LIMIT 10
            ''').fetchall()
            
            report['recent_tests'] = [dict(test) for test in recent_tests]
            
            # Service health summary
            health_checks = conn.execute('''
                SELECT service_name, region, status, response_time_ms, last_check
                FROM service_health
                WHERE last_check >= datetime('now', '-1 hour')
                ORDER BY last_check DESC
            ''').fetchall()
            
            report['service_health'] = [dict(health) for health in health_checks]
            
            # Generate recommendations
            recommendations = []
            
            # Check for plans without recent tests
            untested_plans = conn.execute('''
                SELECT p.name FROM dr_plans p
                LEFT JOIN dr_executions e ON p.id = e.plan_id AND e.execution_type = 'test' 
                    AND e.started_at >= date('now', '-90 days')
                WHERE e.id IS NULL
            ''').fetchall()
            
            if untested_plans:
                recommendations.append(f"Test {len(untested_plans)} DR plans that haven't been tested in 90 days")
            
            # Check for unhealthy services
            unhealthy_services = [h for h in report['service_health'] if h['status'] == 'unhealthy']
            if unhealthy_services:
                recommendations.append(f"Address {len(unhealthy_services)} unhealthy services")
            
            report['recommendations'] = recommendations
            
            return report
            
        finally:
            conn.close()